from fastapi import FastAPI, APIRouter, HTTPException, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, StreamingResponse
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict
import uuid
from datetime import datetime, timezone
import requests
from bs4 import BeautifulSoup
import aiofiles
from PIL import Image
import io
import asyncio
from urllib.parse import urljoin, urlparse
from emergentintegrations.llm.chat import LlmChat, UserMessage
import unicodedata
import re

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# LLM API Keys
EMERGENT_LLM_KEY = os.environ.get('EMERGENT_LLM_KEY')
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')

# Multiple Google API Keys for failover
GOOGLE_API_KEYS = [
    "AIzaSyDZaFsKqNMXs-Ni2Cr-w9hHhUqPqB8gKjs",
    "AIzaSyD4Nz1llcsVKkiWv2txzpAJnf_i6QqQl3I",
    "AIzaSyDhMC5X_es42QaUnDQi9YwwtaVLYcSpiE4"
]

# API Key Manager for automatic failover
class APIKeyManager:
    """Manages multiple API keys with automatic failover on rate limits"""
    
    def __init__(self, keys: List[str]):
        self.keys = keys
        self.current_index = 0
    
    def get_current_key(self) -> str:
        """Get the current API key"""
        return self.keys[self.current_index]
    
    def get_next_key(self) -> str:
        """Rotate to the next API key"""
        self.current_index = (self.current_index + 1) % len(self.keys)
        return self.keys[self.current_index]
    
    def reset(self):
        """Reset to the first key"""
        self.current_index = 0
    
    async def try_with_all_keys(self, func, *args, **kwargs):
        """
        Try executing a function with all available API keys.
        Automatically switches to next key on rate limit or quota errors.
        """
        last_error = None
        attempted_keys = []
        
        for attempt in range(len(self.keys)):
            current_key = self.get_current_key()
            attempted_keys.append(current_key[-4:])  # Log last 4 chars for debugging
            
            try:
                logging.info(f"Attempting API call with key ending in ...{current_key[-4:]} (attempt {attempt + 1}/{len(self.keys)})")
                result = await func(current_key, *args, **kwargs)
                logging.info(f"‚úÖ Success with key ending in ...{current_key[-4:]}")
                # Success! Rotate to next key for next call (round-robin)
                self.get_next_key()
                return result
                
            except Exception as e:
                error_msg = str(e).lower()
                last_error = e
                
                # Check if it's a rate limit or quota error
                if any(keyword in error_msg for keyword in ['rate limit', 'quota', 'overload', '429', 'resource exhausted', 'too many requests']):
                    logging.warning(f"‚ö†Ô∏è Rate limit/quota error with key ...{current_key[-4:]}: {str(e)[:100]}")
                    # Try next key
                    self.get_next_key()
                    continue
                else:
                    # For other errors, don't try other keys (likely a code/input issue)
                    logging.error(f"‚ùå Non-recoverable error with key ...{current_key[-4:]}: {str(e)[:100]}")
                    raise e
        
        # All keys failed
        logging.error(f"‚ùå All {len(self.keys)} API keys failed. Attempted keys ending in: {attempted_keys}")
        raise HTTPException(
            status_code=503,
            detail=f"All API keys are currently overloaded or have reached quota limits. Please try again later. (Tried {len(attempted_keys)} keys)"
        )

# Initialize the key manager
api_key_manager = APIKeyManager(GOOGLE_API_KEYS)

# Create images directory
IMAGES_DIR = ROOT_DIR / 'static' / 'images'
IMAGES_DIR.mkdir(parents=True, exist_ok=True)

# Create the main app
app = FastAPI()

# Mount static files
app.mount("/static", StaticFiles(directory=str(ROOT_DIR / "static")), name="static")

# Create API router
api_router = APIRouter(prefix="/api")

# Models
class SocialContent(BaseModel):
    model_config = ConfigDict(extra="ignore")
    facebook: Optional[str] = None
    twitter: Optional[str] = None
    hashtags: Optional[str] = None

class ImageMetadata(BaseModel):
    model_config = ConfigDict(extra="ignore")
    url: str
    alt_text: str
    filename: str

class Project(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    title: str
    source_url: Optional[str] = None
    original_content: str
    translated_content: Optional[str] = None
    social_content: Optional[SocialContent] = None
    images: List[str] = Field(default_factory=list)  # Keep for backward compatibility
    image_metadata: List[ImageMetadata] = Field(default_factory=list)  # New field for image details
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class ProjectCreate(BaseModel):
    source_url: Optional[str] = None
    raw_text: Optional[str] = None

class ProjectUpdate(BaseModel):
    translated_content: str

class TranslateRequest(BaseModel):
    content: str
    custom_preset: str = ""

class SocialGenerateRequest(BaseModel):
    content: str
    custom_preset: str = ""

class KOLPost(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    information_source: str  # Can be text or URL
    insight_required: str
    generated_content: Optional[str] = None
    source_type: str = "text"  # "text" or "url"
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class KOLPostCreate(BaseModel):
    information_source: str
    insight_required: str
    source_type: str = "text"

class KOLPostGenerate(BaseModel):
    information_source: str
    insight_required: str
    source_type: str = "text"

class NewsArticle(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    source_content: str  # English content - text or URL
    opinion: Optional[str] = None  # Optional user opinion/comment
    style_choice: str = "auto"  # "auto", "style1", "style2"
    generated_content: Optional[str] = None
    source_type: str = "text"  # "text" or "url"
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class NewsArticleGenerate(BaseModel):
    source_content: str
    opinion: Optional[str] = None
    style_choice: str = "auto"
    source_type: str = "text"

class NewsArticleUpdate(BaseModel):
    generated_content: str

class SocialPost(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    website_link: Optional[str] = None  # URL to GFI Research article (optional now)
    website_content: Optional[str] = None  # Text content (optional)
    source_type: str = "url"  # "url" or "text"
    title: Optional[str] = None  # Optional - AI will generate if empty
    introduction: Optional[str] = None  # Optional - AI will generate if empty
    highlight: Optional[str] = None  # Optional - AI will generate if empty
    generated_content: Optional[str] = None  # Final generated social post
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class SocialPostGenerate(BaseModel):
    website_link: Optional[str] = None
    website_content: Optional[str] = None
    source_type: str = "url"
    title: Optional[str] = None
    introduction: Optional[str] = None
    highlight: Optional[str] = None

class SocialPostUpdate(BaseModel):
    generated_content: str

# Helper functions
async def download_image(image_url: str, project_id: str) -> Optional[str]:
    """Download image and return local path"""
    try:
        response = requests.get(image_url, timeout=10, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        response.raise_for_status()
        
        # Create project directory
        project_dir = IMAGES_DIR / project_id
        project_dir.mkdir(exist_ok=True)
        
        # Generate filename
        parsed_url = urlparse(image_url)
        filename = Path(parsed_url.path).name or f"image_{uuid.uuid4().hex[:8]}.jpg"
        if not filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')):
            filename += '.jpg'
        
        filepath = project_dir / filename
        
        # Save image
        async with aiofiles.open(filepath, 'wb') as f:
            await f.write(response.content)
        
        # Return relative path for URL
        return f"/static/images/{project_id}/{filename}"
    except Exception as e:
        logging.error(f"Error downloading image {image_url}: {e}")
        return None

def remove_vietnamese_accents(text: str) -> str:
    """Remove Vietnamese accents from text"""
    # Normalize unicode characters
    text = unicodedata.normalize('NFD', text)
    # Remove combining characters (accents)
    text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')
    return text

async def batch_translate_to_vietnamese_slugs(texts: List[str]) -> List[str]:
    """Batch translate multiple English texts to Vietnamese slug format in one API call"""
    if not texts:
        return []
    
    # Define the translation function that will be tried with multiple keys
    async def _translate_with_key(api_key: str):
        llm = LlmChat(
            api_key=api_key,
            session_id=f"batch_translate_{uuid.uuid4().hex[:8]}",
            system_message="You are a translator. Translate English to simple, natural Vietnamese."
        ).with_model("gemini", "gemini-2.0-flash-exp")
        
        # Create numbered list for batch translation
        numbered_texts = "\n".join([f"{i+1}. {text}" for i, text in enumerate(texts)])
        
        prompt = f"""Translate these {len(texts)} English texts to Vietnamese (simple, natural translation).
Return ONLY the Vietnamese translations, one per line, numbered 1-{len(texts)}.
Do NOT add explanations or extra text.

{numbered_texts}"""
        
        user_message = UserMessage(text=prompt)
        response_obj = await llm.send_message(user_message)
        return response_obj.strip()
    
    try:
        # Try with all available API keys
        response_text = await api_key_manager.try_with_all_keys(_translate_with_key)
        
        # Parse response - extract translations
        translations = []
        lines = response_text.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            # Remove numbering (e.g., "1. ", "2. ", etc.)
            translation = re.sub(r'^\d+\.\s*', '', line)
            if translation:
                translations.append(translation)
        
        # If we didn't get enough translations, pad with originals
        while len(translations) < len(texts):
            translations.append(texts[len(translations)])
        
        # Convert each translation to slug
        slugs = []
        for vietnamese_text in translations[:len(texts)]:
            # Remove accents
            no_accent = remove_vietnamese_accents(vietnamese_text)
            
            # Convert to lowercase
            no_accent = no_accent.lower()
            
            # Replace spaces and special characters with hyphens
            slug = re.sub(r'[^a-z0-9]+', '-', no_accent)
            
            # Remove leading/trailing hyphens
            slug = slug.strip('-')
            
            # Remove consecutive hyphens
            slug = re.sub(r'-+', '-', slug)
            
            slugs.append(slug)
        
        return slugs
    except Exception as e:
        logging.error(f"Error batch translating texts: {e}")
        # Fallback: convert English to slugs
        slugs = []
        for text in texts:
            no_accent = text.lower()
            slug = re.sub(r'[^a-z0-9]+', '-', no_accent)
            slug = slug.strip('-')
            slug = re.sub(r'-+', '-', slug)
            slugs.append(slug)
        return slugs

async def scrape_content(url: str, project_id: str) -> Dict:
    """Scrape content from URL and download images"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extract title
        title = soup.find('title')
        title_text = title.get_text().strip() if title else "Untitled"
        
        # FIRST: Extract images BEFORE removing elements
        image_data_list = []  # Store temp image data
        images_downloaded = []
        
        # Find all images in the page
        all_imgs = soup.find_all('img')
        
        for idx, img in enumerate(all_imgs):
            src = img.get('src') or img.get('data-src')
            if not src:
                continue
            
            # Filter out unwanted images by checking parent containers and classes
            skip = False
            
            # Skip if in navigation, menu, footer, sidebar
            for parent in img.parents:
                parent_class = ' '.join(parent.get('class', [])).lower() if parent.get('class') else ''
                parent_tag = parent.name if parent.name else ''
                parent_id = (parent.get('id') or '').lower()
                
                # Skip these containers
                if any(term in parent_class for term in ['navigation', 'menu', 'footer', 'sidebar', 'widget', 'related']):
                    skip = True
                    break
                if any(term in parent_id for term in ['nav', 'menu', 'footer', 'sidebar', 'widget']):
                    skip = True
                    break
                if parent_tag == 'footer':
                    skip = True
                    break
                # Keep header images if they're featured/article images
                if parent_tag in ['nav']:
                    skip = True
                    break
            
            # Skip author/profile/avatar images (usually small)
            img_class = ' '.join(img.get('class', [])).lower() if img.get('class') else ''
            if any(term in img_class for term in ['avatar', 'profile', 'author-image', 'author-profile']):
                skip = True
            
            # Skip logo images
            alt_text_check = (img.get('alt') or '').lower()
            if 'logo' in alt_text_check and len(alt_text_check) < 20:  # Short alt text with "logo" is usually a logo
                skip = True
            
            if skip:
                continue
                
            # Make absolute URL
            absolute_url = urljoin(url, src)
            
            # Get alt text
            alt_text = img.get('alt', '').strip()
            if not alt_text:
                alt_text = img.get('title', '').strip()
            if not alt_text:
                alt_text = f"image-{len(image_data_list)+1}"
            
            # Store temp data
            image_data_list.append({
                'url': absolute_url,
                'alt_text': alt_text
            })
        
        # BATCH TRANSLATE all alt texts at once (much faster!)
        alt_texts = [img['alt_text'] for img in image_data_list]
        vietnamese_slugs = await batch_translate_to_vietnamese_slugs(alt_texts)
        
        # Now create final metadata with translated filenames
        image_metadata = []
        for i, img_data in enumerate(image_data_list):
            vietnamese_slug = vietnamese_slugs[i] if i < len(vietnamese_slugs) else img_data['alt_text'].lower()
            filename = f"{vietnamese_slug}.jpg"
            
            image_metadata.append({
                'url': img_data['url'],
                'alt_text': img_data['alt_text'],
                'filename': filename
            })
            
            # Download image for preview
            local_path = await download_image(img_data['url'], project_id)
            if local_path:
                images_downloaded.append(local_path)
        
        # NOW: Remove script and style elements from soup copy for content extraction
        soup_copy = BeautifulSoup(str(soup), 'html.parser')
        for script in soup_copy(['script', 'style', 'nav', 'footer', 'header']):
            script.decompose()
        
        # Find main content (try common content containers)
        content = None
        for selector in ['article', 'main', '.content', '#content', '.post-content', '.entry-content']:
            content = soup_copy.select_one(selector)
            if content:
                break
        
        if not content:
            content = soup_copy.find('body')
        
        # Get HTML content
        html_content = str(content) if content else ""
        
        return {
            'title': title_text,
            'content': html_content,
            'images': images_downloaded,
            'image_metadata': image_metadata
        }
    except Exception as e:
        logging.error(f"Error scraping {url}: {e}")
        raise HTTPException(status_code=400, detail=f"Failed to scrape URL: {str(e)}")

# API Routes
@api_router.get("/")
async def root():
    return {"message": "Partner Content Hub API"}

@api_router.post("/projects", response_model=Project)
async def create_project(input: ProjectCreate):
    """Create a new project from URL or raw text"""
    project_id = str(uuid.uuid4())
    
    if input.source_url:
        # Scrape content from URL
        scraped_data = await scrape_content(input.source_url, project_id)
        project_data = {
            'id': project_id,
            'title': scraped_data['title'],
            'source_url': input.source_url,
            'original_content': scraped_data['content'],
            'images': scraped_data['images'],
            'image_metadata': scraped_data.get('image_metadata', []),
            'created_at': datetime.now(timezone.utc),
            'updated_at': datetime.now(timezone.utc)
        }
    elif input.raw_text:
        # Use raw text
        project_data = {
            'id': project_id,
            'title': 'Untitled Project',
            'original_content': input.raw_text,
            'images': [],
            'image_metadata': [],
            'created_at': datetime.now(timezone.utc),
            'updated_at': datetime.now(timezone.utc)
        }
    else:
        raise HTTPException(status_code=400, detail="Either source_url or raw_text must be provided")
    
    # Save to database
    doc = project_data.copy()
    doc['created_at'] = doc['created_at'].isoformat()
    doc['updated_at'] = doc['updated_at'].isoformat()
    
    await db.projects.insert_one(doc)
    
    return Project(**project_data)

@api_router.get("/projects", response_model=List[Project])
async def get_projects():
    """Get all projects"""
    projects = await db.projects.find({}, {"_id": 0}).sort('created_at', -1).to_list(1000)
    
    # Convert ISO strings to datetime
    for project in projects:
        if isinstance(project.get('created_at'), str):
            project['created_at'] = datetime.fromisoformat(project['created_at'])
        if isinstance(project.get('updated_at'), str):
            project['updated_at'] = datetime.fromisoformat(project['updated_at'])
    
    return projects

@api_router.get("/projects/{project_id}", response_model=Project)
async def get_project(project_id: str):
    """Get a specific project"""
    project = await db.projects.find_one({"id": project_id}, {"_id": 0})
    
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")
    
    # Convert ISO strings to datetime
    if isinstance(project.get('created_at'), str):
        project['created_at'] = datetime.fromisoformat(project['created_at'])
    if isinstance(project.get('updated_at'), str):
        project['updated_at'] = datetime.fromisoformat(project['updated_at'])
    
    return Project(**project)

@api_router.put("/projects/{project_id}", response_model=Project)
async def update_project(project_id: str, update: ProjectUpdate):
    """Update project's translated content"""
    result = await db.projects.update_one(
        {"id": project_id},
        {
            "$set": {
                "translated_content": update.translated_content,
                "updated_at": datetime.now(timezone.utc).isoformat()
            }
        }
    )
    
    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="Project not found")
    
    return await get_project(project_id)

@api_router.delete("/projects/{project_id}")
async def delete_project(project_id: str):
    """Delete a project"""
    result = await db.projects.delete_one({"id": project_id})
    
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Project not found")
    
    return {"message": "Project deleted successfully", "id": project_id}

@api_router.get("/download-image")
async def download_image_proxy(url: str, filename: str):
    """Proxy endpoint to download images from external URLs with custom filename"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15, stream=True)
        response.raise_for_status()
        
        # Get content type
        content_type = response.headers.get('content-type', 'image/jpeg')
        
        # Return streaming response with custom filename
        from fastapi.responses import StreamingResponse
        
        def iterfile():
            for chunk in response.iter_content(chunk_size=8192):
                yield chunk
        
        return StreamingResponse(
            iterfile(),
            media_type=content_type,
            headers={
                "Content-Disposition": f'attachment; filename="{filename}"'
            }
        )
    except Exception as e:
        logging.error(f"Error downloading image from {url}: {e}")
        raise HTTPException(status_code=400, detail=f"Failed to download image: {str(e)}")


@api_router.post("/projects/{project_id}/translate")
async def translate_content(project_id: str, request: TranslateRequest):
    """Translate and restructure content using Gemini with user's preset prompt"""
    
    # Define the translation function that will be tried with multiple keys
    async def _translate_with_key(api_key: str):
        chat = LlmChat(
            api_key=api_key,
            session_id=f"translate_{project_id}",
            system_message="B·∫°n l√† m·ªôt chuy√™n gia vi·∫øt b√°o v·ªÅ crypto."
        ).with_model("gemini", "gemini-2.5-pro")
        
        # Build custom preset addition if provided
        custom_instructions = ""
        if request.custom_preset:
            custom_instructions = f"\n\nY√äU C·∫¶U B·ªî SUNG T·ª™ NG∆Ø·ªúI D√ôNG:\n{request.custom_preset}\n"
        
        # Use exact user preset prompt with HTML format requirement
        prompt = f"""T√¥i y√™u c·∫ßu b·∫°n, nhi·ªám v·ª• ch√≠nh l√†: 
-V·ªõi m·ªói n·ªôi dung t√¥i g·ª≠i b·∫°n, ƒë√≥ l√† b√†i article, b·∫°n h√£y d·ªãch sang ti·∫øng vi·ªát v√† ƒë·ªïi phong c√°ch vi·∫øt th√†nh c√°ch vi·∫øt c·ªßa c√°c b√™n b√°o VN, kh√¥ng qu√° shill d·ª± √°n, gi·ªØ c√°c thu·∫≠t ng·ªØ crypto nh√©, v√† v·∫´n gi·ªØ format heading.
- C√°c heading v√† title ch·ªâ vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu ti√™n trong c√¢u ho·∫∑c t·ª´ kho√° quan tr·ªçng.
- ƒê·ªÉ th√™m c√°c b·∫£n d·ªãch ti·∫øng Vi·ªát trong d·∫•u ngo·∫∑c ƒë∆°n cho t·∫•t c·∫£ c√°c thu·∫≠t ng·ªØ crypto kh√≥ hi·ªÉu nh√©
- C√°c heading, ƒë·ªïi c√°ch vi·∫øt cho chuy√™n nghi·ªáp, ƒë·ª° cringe h∆°n
- ƒêo·∫°n ƒë·∫ßu ti√™n lu√¥n l√† "Gi·ªõi thi·ªáu" ƒëo·∫°n cu·ªëi c√πng lu√¥n l√† ƒëo·∫°n c√≥ heading l√† "K·∫øt lu·∫≠n"
- Thay "c√¥ng ty" th√†nh "d·ª± √°n" (n·∫øu c√≥)
- Thay "ch√∫ng t√¥i" ho·∫∑c c√°c ng√¥i th·ª© nh·∫•t th√†nh "d·ª± √°n"/"ƒë·ªôi ng≈©"
- ƒê·ª´ng th√™m t·ª´ "c√°c b·∫°n", h√£y d√πng "ng∆∞·ªùi d√πng",...
- Tr·ª´ c√°c t·ª´ ng·ªØ ti·∫øng anh n√†y th√¨ gi·ªØ nguy√™n t·ª´ g·ªëc, c√≤n l·∫°i d·ªãch sang ti·∫øng vi·ªát cho ng∆∞·ªùi d√πng crypto hi·ªÉu, nh·∫•n m·∫°nh l√† ng∆∞·ªùi d√πng crypto (nghƒ©a l√† h·ªç ƒë·ªß hi·ªÉu c∆° b·∫£n v·ªÅ crypto, ƒë·ª´ng d·ªãch qu√° tr·ª´u t∆∞·ª£ng): Blockchain
Private Key / Public Key
Seed Phrase
Staking
Yield Farming
Token vs Coin
Stablecoin
Market Cap
Gas Fee
Smart Contract
NFT (Non-Fungible Token)
DAO (Decentralized Autonomous Organization)
Airdrop
IDO / ICO / IEO
DeFi (Decentralized Finance)
CeFi (Centralized Finance)
TVL (Total Value Locked)
DEX Aggregator
Slippage
Arbitrage
Bridge
Layer 1 / Layer 2
Cross-chain
Validator / Node
Consensus (PoW, PoS, Delegated PoS, ‚Ä¶)
Halving
Liquidity Mining
Impermanent Loss
Rug Pull
Whitelist
Mainnet / Testnet
Protocol
Governance Token
- B·∫°n b√¢y gi·ªù l√† m·ªôt chuy√™n gia vi·∫øt b√°o, to√†n quy·ªÅn quy·∫øt ƒë·ªãnh l∆∞·ª£t b·ªè nh·ªØng ƒëo·∫°n promotion kh√¥ng c·∫ßn thi·∫øt khi vi·∫øt b√°o v·ªÅ m·ªôt d·ª± √°n
{custom_instructions}
QUAN TR·ªåNG - FORMAT OUTPUT:
- Tr·∫£ v·ªÅ HTML format v·ªõi c·∫•u tr√∫c CH·ªà 3 PH·∫¶N:

1. TITLE (Ti√™u ƒë·ªÅ b√†i vi·∫øt):
<h1>Ti√™u ƒë·ªÅ b√†i vi·∫øt ti·∫øng Vi·ªát</h1>

2. META DESCRIPTION (T·ªëi ƒëa 2-3 l·∫ßn ƒë·ªô d√†i c·ªßa title):
<div class="meta-description">
<p>Meta description ng·∫Øn g·ªçn, ch·ªâ 2-3 c√¢u, t·ªëi ƒëa 2-3 l·∫ßn ƒë·ªô d√†i c·ªßa ti√™u ƒë·ªÅ</p>
</div>

3. MAIN CONTENT (Bao g·ªìm Sapo v√† to√†n b·ªô n·ªôi dung c√≤n l·∫°i):
<div class="main-content">
<p><strong>Sapo:</strong> ƒêo·∫°n sapo kho·∫£ng 100 t·ª´</p>
<h2>Gi·ªõi thi·ªáu</h2>
<p>N·ªôi dung gi·ªõi thi·ªáu...</p>
... (c√°c section kh√°c)
<h2>K·∫øt lu·∫≠n</h2>
<p>N·ªôi dung k·∫øt lu·∫≠n...</p>
</div>

- Heading cao nh·∫•t trong main content l√† <h2> (KH√îNG d√πng h1, ƒë√£ d√πng cho title)
- Sub-heading d√πng <h3>
- ƒêo·∫°n vƒÉn d√πng <p>
- Kh√¥ng th√™m l·ªùi gi·∫£i th√≠ch nh∆∞ "Ch·∫Øc ch·∫Øn r·ªìi..." - ch·ªâ tr·∫£ v·ªÅ HTML thu·∫ßn t√∫y
- Meta description ph·∫£i NG·∫ÆN G·ªåN, ch·ªâ 2-3 l·∫ßn ƒë·ªô d√†i c·ªßa title

N·ªôi dung:
{request.content}"""
        
        user_message = UserMessage(text=prompt)
        response = await chat.send_message(user_message)
        
        # Clean up markdown code blocks if present
        cleaned_response = response.strip()
        if cleaned_response.startswith('```html'):
            cleaned_response = cleaned_response[7:]  # Remove ```html
        elif cleaned_response.startswith('```'):
            cleaned_response = cleaned_response[3:]  # Remove ```
        
        if cleaned_response.endswith('```'):
            cleaned_response = cleaned_response[:-3]  # Remove trailing ```
        
        return cleaned_response.strip()
    
    try:
        # Try with all available API keys
        cleaned_response = await api_key_manager.try_with_all_keys(_translate_with_key)
        
        # Update database
        await db.projects.update_one(
            {"id": project_id},
            {
                "$set": {
                    "translated_content": cleaned_response,
                    "updated_at": datetime.now(timezone.utc).isoformat()
                }
            }
        )
        
        return {"translated_content": cleaned_response}
    
    except Exception as e:
        logging.error(f"Translation error: {e}")
        raise HTTPException(status_code=500, detail=f"Translation failed: {str(e)}")

@api_router.post("/projects/{project_id}/social")
async def generate_social_content(project_id: str, request: SocialGenerateRequest):
    """Generate social media content using Gemini with user's preset prompt"""
    
    # Define the generation function that will be tried with multiple keys
    async def _generate_with_key(api_key: str):
        chat = LlmChat(
            api_key=api_key,
            session_id=f"social_{project_id}",
            system_message="B·∫°n l√† m·ªôt ng∆∞·ªùi qu·∫£n l√Ω c·ªông ƒë·ªìng (Community Manager) cho m·ªôt k√™nh tin t·ª©c v·ªÅ crypto."
        ).with_model("gemini", "gemini-2.0-flash-exp")
        
        # Build custom preset addition if provided
        custom_instructions = ""
        if request.custom_preset:
            custom_instructions = f"\n\nY√äU C·∫¶U B·ªî SUNG T·ª™ NG∆Ø·ªúI D√ôNG:\n{request.custom_preset}\n"
        
        # Combined preset with examples from Partner (m·ªõi).pdf
        prompt = f"""ok gi·ªù ƒë·ªçc b√†i ƒë√≥ v√† h√£y vi·∫øt b√†i post telegram ng·∫Øn cho t√¥i nh√©, kho·∫£ng 100 t·ª´ th√¥i, theo outline sau: title d·∫´n d·∫Øt c√°c v·∫•n ƒë·ªÅ hi·ªán t·∫°i c·ªßa th·ªã tr∆∞·ªùng sau ƒë√≥ gi·ªõi thi·ªáu 1 ph·∫ßn n·ªôi dung c√≥ insight (ng·∫Øn, sao cho ƒë·ª´ng qu√° shill d·ª± √°n) k·∫øt lu·∫≠n v√† CTA v·ªÅ b√†i GFI Research g·ªëc
{custom_instructions}
Y√äU C·∫¶U FORMAT OUTPUT:
- Vi·∫øt th√†nh 1 b√†i post li·ªÅn m·∫°ch, KH√îNG C√ì labels nh∆∞ "Ti√™u ƒë·ªÅ:", "N·ªôi dung:", "CTA:"
- D√≤ng ƒë·∫ßu ti√™n: Ti√™u ƒë·ªÅ c·ªßa b√†i (kh√¥ng c·∫ßn label) - S·ª¨ D·ª§NG EMOJI üî• ho·∫∑c ü§î ·ªü ƒë·∫ßu ti√™u ƒë·ªÅ
- Sau ƒë√≥ xu·ªëng d√≤ng v√† vi·∫øt n·ªôi dung ch√≠nh
- N·ªôi dung ch√≠nh chia th√†nh 2 ƒëo·∫°n vƒÉn (m·ªói ƒëo·∫°n c√¢n ƒë·ªëi ƒë·ªô d√†i), ngƒÉn c√°ch b·ªüi 1 d√≤ng tr·ªëng
- S·ª≠ d·ª•ng emojis ph√π h·ª£p trong n·ªôi dung: üôÇ ‚û°Ô∏è üéØ ü§î (2-3 emojis trong b√†i)
- ƒêo·∫°n cu·ªëi: CTA v·ªÅ GFI Research v·ªõi emoji ‚û°Ô∏è v√† link ƒë·∫ßy ƒë·ªß
- T·ªïng c·ªông: Ti√™u ƒë·ªÅ + 2 ƒëo·∫°n n·ªôi dung + 1 ƒëo·∫°n CTA

OUTLINE C·ª¶A B√ÄI POST:
- Ti√™u ƒë·ªÅ (d√≤ng ƒë·∫ßu) - c√≥ emoji üî• ho·∫∑c ü§î
- N·ªôi dung ch√≠nh ƒëo·∫°n 1 (context v√† v·∫•n ƒë·ªÅ)
- N·ªôi dung ch√≠nh ƒëo·∫°n 2 (insight v√† detail k·ªπ thu·∫≠t) - c√≥ emoji nh∆∞ üôÇ ‚û°Ô∏è üéØ
- CTA v·ªÅ b√†i vi·∫øt g·ªëc GFI Research - c√≥ emoji ‚û°Ô∏è v√† link

L∆∞u √Ω: 
- Vi·∫øt v·ªõi g√≥c nh√¨n th·ª© ba, kh√¥ng shill d·ª± √°n
- S·ª≠ d·ª•ng emojis t·ª± nhi√™n, kh√¥ng l·∫°m d·ª•ng (2-3 emojis t·ªïng c·ªông)
- Lu√¥n c√≥ link ƒë·∫ßy ƒë·ªß trong CTA

V√ç D·ª§ THAM KH·∫¢O (3 examples v·ªõi format m·ªõi):

Example 1 - B√†i v·ªÅ SP1 Hypercube (format ƒë√∫ng v·ªõi emojis):
üî• T·∫°o b·∫±ng ch·ª©ng kh·ªëi Ethereum ch·ªâ trong 12 gi√¢y: B√†i to√°n t·ªëc ƒë·ªô cho ZK rollups

M·ªôt trong nh·ªØng r√†o c·∫£n l·ªõn cho ZK rollups tr√™n Ethereum l√† th·ªùi gian t·∫°o b·∫±ng ch·ª©ng. M·ª•c ti√™u l√† proving d∆∞·ªõi 12 gi√¢y, th·ªùi gian slot c·ªßa Ethereum, ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c finality th·ª±c s·ª± th·ªùi gian th·ª±c.

üôÇ SP1 Hypercube ƒëang th·ª≠ nghi·ªám c√°ch ti·∫øp c·∫≠n m·ªõi v·ªõi ƒëa th·ª©c ƒëa tuy·∫øn thay v√¨ ƒëa th·ª©c ƒë∆°n bi·∫øn truy·ªÅn th·ªëng. AE nghƒ© ƒë√¢y c√≥ ph·∫£i l√† ƒë·ªôt ph√° th·ª±c s·ª± cho ZK Ethereum, hay v·∫´n c√≤n xa m·ªõi ƒë·∫øn s·ª± c√¥ng nh·∫≠n r·ªông r√£i do y√™u c·∫ßu ph·∫ßn c·ª©ng?

C√πng GFI kh√°m ph√° chi ti·∫øt t·∫°i ‚û°Ô∏è SP1 Hypercube: zkVM cho ph√©p t·∫°o b·∫±ng ch·ª©ng Ethereum trong th·ªùi gian th·ª±c (https://gfiresearch.net/sp1-hypercube-zkvm-cho-phep-tao-bang-chung-ethereum-trong-thoi-gian-thuc)

Example 2 - B√†i v·ªÅ Succinct (format ƒë√∫ng v·ªõi emojis):
ü§î B√†i to√°n v·ªÅ chi ph√≠ v√† kh·∫£ nƒÉng ti·∫øp c·∫≠n c·ªßa ZK Proof

Vi·ªác t·∫°o Zero-Knowledge Proof hi·ªán v·∫´n ƒë√≤i h·ªèi c∆° s·ªü h·∫° t·∫ßng ph·ª©c t·∫°p v√† chi ph√≠ cao, h·∫°n ch·∫ø kh·∫£ nƒÉng √°p d·ª•ng r·ªông r√£i. C√°c d·ª± √°n th∆∞·ªùng ph·∫£i t·ª± v·∫≠n h√†nh prover ho·∫∑c ph·ª• thu·ªôc v√†o nh√† cung c·∫•p t·∫≠p trung.

‚û°Ô∏è V√¨ v·∫≠y, Succinct ƒëang th·ª≠ nghi·ªám m√¥ h√¨nh marketplace hai chi·ªÅu, k·∫øt n·ªëi ng∆∞·ªùi c·∫ßn ZK proof v·ªõi prover th√¥ng qua ƒë·∫•u gi√°. ƒêi·ªÉm ƒë√°ng ch√∫ √Ω l√† ki·∫øn tr√∫c t√°ch bi·ªát: auctioneer off-chain cho t·ªëc ƒë·ªô cao, settlement on-chain Ethereum cho b·∫£o m·∫≠t. Token $PROVE v·ª´a l√† ph∆∞∆°ng ti·ªán thanh to√°n, v·ª´a l√†m c∆° ch·∫ø staking ƒë·ªÉ r√†ng bu·ªôc tr√°ch nhi·ªám prover.

ü§î Li·ªáu m√¥ h√¨nh marketplace n√†y c√≥ t·∫°o ra th·ªã tr∆∞·ªùng ZK proof hi·ªáu qu·∫£ h∆°n, hay v·∫´n ch·ªâ ph√π h·ª£p cho m·ªôt s·ªë use case nh·∫•t ƒë·ªãnh?

ƒê·ªçc ph√¢n t√≠ch chi ti·∫øt v·ªÅ ki·∫øn tr√∫c c·ªßa Succinct t·∫°i ‚û°Ô∏è Ki·∫øn tr√∫c M·∫°ng l∆∞·ªõi Succinct v√† token $PROVE (https://gfiresearch.net/kien-truc-mang-luoi-succinct-va-token-prove)

Example 3 - B√†i v·ªÅ BitVM (format ƒë√∫ng v·ªõi emojis):
üî• Bitcoin Script v√† b√†i to√°n ·ª©ng d·ª•ng ph·ª©c t·∫°p: Li·ªáu ZK Proof c√≥ l√† l·ªùi gi·∫£i?

Bitcoin Script (Ng√¥n ng·ªØ l·∫≠p tr√¨nh c·ªßa Bitcoin) ƒë∆∞·ª£c thi·∫øt k·∫ø kh√¥ng ho√†n ch·ªânh v·ªÅ t√≠nh to√°n ƒë·ªÉ t·ªëi ∆∞u b·∫£o m·∫≠t, nh∆∞ng ƒëi·ªÅu n√†y c≈©ng h·∫°n ch·∫ø kh·∫£ nƒÉng x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng ph·ª©c t·∫°p nh∆∞ rollup hay bridge phi t√≠n nhi·ªám tr√™n Bitcoin.

üéØ BitVM ƒëang th·ª≠ nghi·ªám c√°ch ti·∫øp c·∫≠n m·ªõi b·∫±ng vi·ªác x√°c minh t√≠nh to√°n thay v√¨ th·ª±c thi tr·ª±c ti·∫øp. ƒêi·ªÉm k·ªπ thu·∫≠t ƒë√°ng ch√∫ √Ω l√† BLAKE3 ch·ªâ c·∫ßn 7 v√≤ng n√©n so v·ªõi 64 v√≤ng c·ªßa SHA256, gi√∫p gi·∫£m ƒë√°ng k·ªÉ chi ph√≠ x√°c minh ZK Proof tr√™n Bitcoin Script. M·ªôt s·ªë d·ª± √°n nh∆∞ Alpen Labs (ZK rollup), Babylon (bridge phi t√≠n nhi·ªám) ƒëang th·ª≠ nghi·ªám m√¥ h√¨nh n√†y. Tuy nhi√™n, li·ªáu c√°ch ti·∫øp c·∫≠n n√†y c√≥ ƒë·ªß hi·ªáu qu·∫£ v√† b·∫£o m·∫≠t cho ·ª©ng d·ª•ng th·ª±c t·∫ø?

C√πng GFI t√¨m hi·ªÉu chi ti·∫øt v·ªÅ h∆∞·ªõng ti·∫øp c·∫≠n kƒ© thu·∫≠t c·ªßa Succinct t·∫°i ‚û°Ô∏è Succinct m·ªü ra kh·∫£ nƒÉng x√°c minh ZK Proof tr√™n Bitcoin th√¥ng qua BitVM (https://gfiresearch.net/succinct-mo-ra-kha-nang-xac-minh-zk-proof-tren-bitcoin-thong-qua-bitvm)

---

B√ÄI VI·∫æT C·∫¶N T·∫†O SOCIAL POST:
{request.content}"""
        
        user_message = UserMessage(text=prompt)
        response = await chat.send_message(user_message)
        
        # Store the Vietnamese social post as a single content piece
        # The response is a ~100 word social media post following the structure:
        # Title ‚Üí Problem/Context ‚Üí Insight ‚Üí CTA
        social_content = {
            'facebook': response.strip(),
            'twitter': '',  # Not used in Vietnamese format
            'hashtags': ''  # Not used in Vietnamese format
        }
        
        # Update database
        await db.projects.update_one(
            {"id": project_id},
            {
                "$set": {
                    "social_content": social_content,
                    "updated_at": datetime.now(timezone.utc).isoformat()
                }
            }
        )
        
        return social_content
    
    except Exception as e:
        logging.error(f"Social content generation error: {e}")
        raise HTTPException(status_code=500, detail=f"Social content generation failed: {str(e)}")

# KOL Post endpoints
@api_router.post("/kol-posts", response_model=KOLPost)
async def create_kol_post(post_data: KOLPostCreate):
    """Create a new KOL post without generating content"""
    post = KOLPost(**post_data.dict())
    await db.kol_posts.insert_one(post.dict())
    return post

@api_router.get("/kol-posts", response_model=List[KOLPost])
async def get_kol_posts():
    """Get all KOL posts"""
    posts = await db.kol_posts.find().sort("created_at", -1).to_list(100)
    return posts

@api_router.get("/kol-posts/{post_id}", response_model=KOLPost)
async def get_kol_post(post_id: str):
    """Get a specific KOL post"""
    post = await db.kol_posts.find_one({"id": post_id})
    if not post:
        raise HTTPException(status_code=404, detail="KOL post not found")
    return post

@api_router.delete("/kol-posts/{post_id}")
async def delete_kol_post(post_id: str):
    """Delete a KOL post"""
    result = await db.kol_posts.delete_one({"id": post_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="KOL post not found")
    return {"message": "KOL post deleted successfully"}

@api_router.post("/kol-posts/generate")
async def generate_kol_post(request: KOLPostGenerate):
    """Generate KOL post content using AI"""
    try:
        # Get information content
        information_content = request.information_source
        
        # If source is URL, scrape the content
        if request.source_type == "url":
            try:
                response = requests.get(request.information_source, timeout=15, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                response.raise_for_status()
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Remove script and style elements
                for script in soup(["script", "style", "nav", "footer", "header", "aside"]):
                    script.decompose()
                
                # Get title
                title = soup.find('title')
                title_text = title.get_text().strip() if title else ""
                
                # Get main content
                main_content = ""
                # Try to find main content areas
                content_areas = soup.find_all(['article', 'main', 'div'], class_=lambda x: x and any(c in str(x).lower() for c in ['content', 'article', 'post', 'entry']))
                if content_areas:
                    main_content = ' '.join([area.get_text(separator=' ', strip=True) for area in content_areas])
                else:
                    # Fallback to all paragraph text
                    paragraphs = soup.find_all('p')
                    main_content = ' '.join([p.get_text(separator=' ', strip=True) for p in paragraphs])
                
                information_content = f"Ti√™u ƒë·ªÅ: {title_text}\n\nN·ªôi dung:\n{main_content}"
                
            except Exception as e:
                raise HTTPException(status_code=400, detail=f"Kh√¥ng th·ªÉ c√†o n·ªôi dung t·ª´ URL: {str(e)}")
        
        # DQ Writing Style from PDF - Complete examples
        writing_style_examples = """
B√†i 1:
Upbit tr∆∞·ªõc delist h·∫øt m·∫•y coin privacy nh∆∞ $XMR, $ZEC v√¨ l√Ω do tu√¢n th·ªß.
Nh∆∞ng gi·ªù l·∫°i list $PROVE, c≈©ng l√† token li√™n quan ƒë·∫øn privacy, nh∆∞ng kh√¥ng b·ªã xem l√† d·∫°ng private currency
C√≥ th·ªÉ do n√≥ thu·ªôc d·∫°ng h·∫° t·∫ßng ZK, d√πng cho x√°c minh v√† m·ªü r·ªông m·∫°ng l∆∞·ªõi ch·ª© kh√¥ng ph·ª•c v·ª• ·∫©n danh giao d·ªãch.
Kh√¥ng bi·∫øt trong t∆∞∆°ng lai c√≥ open ra ƒë·ªÉ list l·∫°i m·∫•y th·∫±ng privacy kh√¥ng, v√¨ lquan ƒë·∫øn r·ª≠a ti·ªÅn th√¨ c≈©ng cƒÉng.
Kh√¥ng ai mu·ªën li√™n ƒë·ªõi c·∫£

B√†i 2:
ƒê·ªát tr∆∞·ªõc c√≥ tia ƒë∆∞·ª£c em n√†y m√† ch·ªù l√¢u n√≥ng ƒë√≠t n√™n thu h·ªìi v·ªÅ dca coin top
N√†o ng·ªù n√≥ ch·ªù m√¨nh b√°n xong l√† n√≥ x8
Cay d√© v·∫≠y ta kkk $ZKWASM
Th√¥i t√¨m gem kh√°c v·∫≠y, alpha t·ª•i n√≥ hay ƒë·∫©y l√°o l·∫Øm ae

B√†i 3:
B√†i vi·∫øt n√†y d√†nh cho ae hay s·ª£ ma voi qu·ª∑ m·∫≠p tr√™n Hyperliquid
D·∫°o n√†y th·∫•y c√°c b√°c follow v√≠ "insider nh√† Trump" nhi·ªÅu v√† h·ªÖ c·ª© th·∫•y n√≥ s·ªçc $BTC th√¨ s·ª£ to√°n lo·∫°n l√™n, v√¨ ƒëa ph·∫ßn ae hold h√†ng nh∆∞ng to√†n mang t√¢m l√≠ trade, √¢m 5 - 10% l√† ƒë√£ th·∫•y ch·ªôt d·∫°.
Th·∫±ng n√†y n√≥ short $BTC volume l·ªõn, l·∫°i c√≤n l√π l√π tr√™n Hyper, ae track ra ƒë∆∞·ª£c n√≥, ƒëƒÉng social t√πm lum c·∫£ trong v√† ngo√†i n∆∞·ªõc, kh√¥ng l·∫Ω n√≥ kh√¥ng bi·∫øt
Y√™n v·ªã gi√πm t c√°i, cu·ªëi m√πa r·ªìi ƒë·ª´ng c√≥ t·ªëi ∆∞u n·ªØa, c√∫ s·∫≠p n√†y kill h·∫øt b·∫©y r·ªìi, m·ª•c ƒë√≠ch l√† ƒë·ªÉ ae r√©n tay kh√¥ng d√°m b·∫©y n·ªØa, t·ª´ ƒë√≥ ƒë·∫©y l√† ch·ªët l·ªùi quy m√¥ l·ªõn h∆°n v√¨ thanh kho·∫£n ƒë√≥ t·ª´ ae m·ªõi l√† thanh kho·∫£n th·∫≠t.
That's it, $ETH szn incoming

B√†i 5:
Qu·∫£ $SNX x2 sau 2 tu·∫ßn, x4 t·ª´ ƒë√°y. M√∫c theo D∆∞∆°ng Qu√° th√¨ Qu√° g√¨ ·∫°, Qu√° ƒë√£
GM ƒë·∫ßu tu·∫ßn c·∫£ nh√†, ƒë√∫ng plan th√¨ m√¨nh l√†m th√¥i, k·ªá m·∫π c√∫ s·∫≠p lu√¥n
Sau ƒë·ª£t liquidate full market th√¨ $SNX v·∫´n l√† 1 trong nh·ªØng c√≤n h√†ng ch·ªãu ·∫£nh h∆∞·ªüng √≠t nh·∫•t, s·∫≠p xong th·ª±c t·∫ø ch·ªâ l√µm 10% so v·ªõi entry c·ªßa D∆∞∆°ng.
V√† c≈©ng may m·∫Øn nh·ªù c√∫ s·∫≠p n√™n k·ªãp th√≥ 1 l·ªánh DCA v√†o, ƒë√∫ng v√πng 0.9 lu√¥n v√¨ 4h s√°ng h√¥m ƒë√≥ th√¨ D∆∞∆°ng ch∆∞a d·∫≠y =))
Th√†nh qu·∫£ cho nh·ªØng chu·ªói ng√†y sideway, x2 ch·ªët g·ªëc l√† ƒë·∫πp. AE v√†o con h√†ng n√†y c√πng D∆∞∆°ng th√¨ c√≥ th·ªÉ ch·ªët g·ªëc nh√©, c√≤n l·∫°i ƒë·ªÉ market t·ª± x·ª≠ l√≠, #Ethereum Eco b·∫Øt ƒë·∫ßu ch·∫°y, uptrend t·ªõi r·ªìi ae ∆°i

B√†i 7:
KINH KH·ª¶NG: S·ªëng ƒë·ªß l√¢u ƒë·ªÉ th·∫•y con s·ªë 20 t·ª∑ d√¥ b·ªã thanh l√Ω
Tr·ª´ $BTC, $ETH c√≤n ƒë·ª° t√≠, t·∫•t c·∫£ altcoin n√°t g√°o, chia bu·ªìn v·ªõi ae long ƒë√≤n b·∫©y, ch·ªâ c·∫ßn 2x l√† ch√°y h·∫øt, kh√¥ng c√≤n gi·ªçt m√°u n√†o lu√¥n.
ƒêi·ªÅu c·∫ßn l√†m hi·ªán t·∫°i l√† b√¨nh tƒ©nh, ch·ªù t·∫°o ƒë√°y ƒë√£, Trung Qu·ªëc ch∆∞a ƒë√°p tr·∫£, c√≤n h√†nh ti·∫øp ƒë√≥ ae ·∫°

B√†i 9:
GM AE, con h√†ng $SNX v·∫´n c·ª©ng ph·∫øt
Chart v·∫´n c√≤n sideway v√† v·∫´n kh√¥ng l·ªßng ƒë∆∞·ª£c entry c·ªßa D∆∞∆°ng, nay ƒë∆∞·ª£c m√πa coin c≈© n√≥ ƒë·∫©y l√™n +20% ngon l√†nh lu√¥n ae ·∫°
Ae n√†o trade l∆∞·ªõt th√¨ ch·ªët v·ª´a m·ªìm ƒë·ª£i entry m·ªõi c≈©ng ƒë∆∞·ª£c v√¨ $BTC ƒëang kh√° d·∫≠p d√¨u.
C√≤n D∆∞∆°ng th√¨ hold ch·∫∑t, s·∫Ω v√†o th√™m v√† target cao h∆°n, v·∫´n bet v√†o perp dex h·ªá Ethereum n√†y

B√†i 11:
Th·∫•y ch∆∞a ae, n·ªï s√∫ng r·ªìi ƒë√≥. Gi√° n√†y c√≤n r·∫ª ch√°n
C·ª© chill chill √¥m m·∫•y em ch·∫•t l∆∞·ª£ng th√¥i kh√¥ng c·∫ßn l√†m g√¨ nhi·ªÅu ae ·∫°
$PLUME on the top, up only (ko ƒë√πa)
P/s: S·∫Ω n√≥i r√µ v·ªÅ tin n√†y sau, nh∆∞ng b√πng l·ªï vl ƒë√≥ ae

B√†i 14:
Uptrend t·ªõi, c√°c d·ª± √°n b·∫Øt ƒë·∫ßu ng√°o gi√°
Anh em c·∫©n th·∫≠n, m·ªõi h√¥m qua c√≥ $FF l√†m m·∫´u r·ªìi ƒë√≥, chia g·∫ßn 10 t·ª´ ƒë·ªânh d√π m·ªõi TGE...1 ng√†y.
ƒê√°nh gi√° k·ªπ d·ª± √°n, ƒë·ª´ng ƒë·ªÉ b·ªã slow rug nh∆∞ nƒÉm ngo√°i nha ae
N√≥i chung t·ªët nh·∫•t m·ªõi list th√¨ ƒë·ª´ng ƒë·ª•ng tay v√†o

B√†i 16:
N·∫øu ae miss c·∫£ $ASTER, $AVNT, $APEX th√¨ c√≥ th·ªÉ m√∫c $SNX, entry now. L√Ω do:
@synthetix_io l√† d·ª± √°n m√πa c≈©, m√πa n√†y s·∫Ω c√≥ ƒë·ªông l·ª±c ƒë·∫©y ƒë·ªÉ ch·ªët s·ªï, c√≤n l√†m d·ª± √°n kh√°c m√πa sau
Chuy·ªÉn sang b√∫ Ethereum theo trend perp dex, v·ªõi trading prize pool $1M
Chart ƒë√£ confirm breakout v·ªõi volume m·∫°nh + v∆∞·ª£t ƒë·ªânh, m·ªëc c·∫£n g·∫ßn nh·∫•t th√¨ ch·ªâ l√† trendline gi·∫£m quanh 1.8, nh∆∞ng c√°c ƒë·ªânh tr∆∞·ªõc ƒë√≥ l√† m·∫•y nƒÉm v·ªÅ tr∆∞·ªõc r·ªìi.
K·ª≥ v·ªçng $ETH pump m·∫°nh v√†o Q4 nƒÉm nay
M·ªôt trong nh·ªØng c√°i thi·∫øu l√† m·ªôt ng∆∞·ªùi d·∫´n s√≥ng, tuy nhi√™n n·∫øu r√µ r√†ng r·ªìi th√¨ kh√¥ng c√≤n entry ƒë·∫πp n·ªØa.
Target g·∫ßn nh·∫•t 1.8, v·ªÅ t·∫ßm 0.9 dca th√™m ƒëo·∫°n n·ªØa, stop loss l√† khi $ETH b·∫Øt ƒë·∫ßu c√≥ d·∫•u hi·ªáu r·ª•ng trong Q4 n√†y.

B√†i 17:
Volume thanh l√Ω $ETH nh·ªØng th√°ng qua bao gi·ªù c≈©ng cao nh·∫•t th·ªã tr∆∞·ªùng.
MM hay th·∫≠t, n√†o ra ph·ªë wall, n√†o l√™n ETF gom, d·ª• cho bullish, max long, xong qu√©t l√† ·∫•m c·∫£ l√†ng
N√≥i v·∫≠y th√¥i ch·ª© qu√©t xong xu√¥i -> chu·∫©n b·ªã ƒë√† tƒÉng m·ªõi
Hold spot v·∫´n t√≠n nha c√°c b√°c, d∆∞·ªõi 4k, t·∫ßm 3k6 -> 3k8 l√† v√πng gi√° ƒë·∫πp ƒë·ªÉ quƒÉng th√™m 1 2 chi·∫øc d√©p l√™n thuy·ªÅn ch·ªù Up to b·ªù ƒë·∫øn.
"""
        
        # System message for KOL writing style
        system_message = f"""B·∫°n l√† m·ªôt KOL crypto c√≥ phong c√°ch vi·∫øt ƒë·∫∑c tr∆∞ng. H·ªçc phong c√°ch vi·∫øt n√†y:

{writing_style_examples}

PHONG C√ÅCH VI·∫æT C·ª¶A B·∫†N:
- Tone casual, th√¢n m·∫≠t v·ªõi ƒë·ªôc gi·∫£ (d√πng "ae", "m√¨nh", "t", "m")
- Nh·∫≠n x√©t ng·∫Øn g·ªçn, kh√¥ng gi·∫£i th√≠ch d√†i d√≤ng
- D√πng ti·∫øng l√≥ng crypto v√† ti·∫øng Vi·ªát t·ª± nhi√™n
- ƒêi th·∫≥ng v√†o v·∫•n ƒë·ªÅ, kh√¥ng lan man
- D√πng c·∫£m th√°n v·ª´a ph·∫£i, kh√¥ng l·∫°m d·ª•ng
- Gi·ªØ ticker crypto v·ªõi $ (v√≠ d·ª•: $BTC, $ETH)
- C√≥ th·ªÉ d√πng emoji nh·∫π nh√†ng
- Vi·∫øt theo ki·ªÉu t√¢m s·ª±, chia s·∫ª quan ƒëi·ªÉm c√° nh√¢n

QUAN TR·ªåNG:
- Nh·∫≠n ƒë·ªãnh ph·∫£i NG·∫ÆN G·ªåN, ƒë√∫ng tr·ªçng t√¢m
- KH√îNG gi·∫£i th√≠ch t√° l·∫£
- KH√îNG l·∫°m d·ª•ng c·∫£m th√°n
- Gi·ªØ phong c√°ch t·ª± nhi√™n nh∆∞ ƒëang chat v·ªõi b·∫°n b√®"""

        # Initialize Gemini chat
        chat = LlmChat(
            api_key=GOOGLE_API_KEY,
            session_id=f"kol_post_{uuid.uuid4().hex[:8]}",
            system_message=system_message
        ).with_model("gemini", "gemini-2.5-pro")
        
        # Create user message
        user_message = UserMessage(f"""ƒê√¢y l√† th√¥ng tin c·∫ßn h·ªçc:

{information_content}

ƒê√¢y l√† nh·∫≠n ƒë·ªãnh c·∫ßn c√≥ (vi·∫øt ng·∫Øn g·ªçn theo nh·∫≠n ƒë·ªãnh n√†y):
{request.insight_required}

H√£y vi·∫øt 1 b√†i post theo phong c√°ch c·ªßa b·∫°n, k·∫øt h·ª£p th√¥ng tin tr√™n v√† nh·∫≠n ƒë·ªãnh ƒë√£ cho. Nh·ªõ: nh·∫≠n ƒë·ªãnh ng·∫Øn g·ªçn, kh√¥ng gi·∫£i th√≠ch d√†i d√≤ng.""")
        
        # Generate content
        response = await chat.send_message(user_message)
        
        # Create and save KOL post
        kol_post = KOLPost(
            information_source=request.information_source,
            insight_required=request.insight_required,
            generated_content=response.strip(),
            source_type=request.source_type
        )
        
        await db.kol_posts.insert_one(kol_post.dict())
        
        return kol_post
    
    except Exception as e:
        logging.error(f"KOL post generation error: {e}")
        raise HTTPException(status_code=500, detail=f"KOL post generation failed: {str(e)}")

# News Generator endpoints
@api_router.post("/news", response_model=NewsArticle)
async def create_news_article(news_data: NewsArticleGenerate):
    """Create a new news article without generating content"""
    news = NewsArticle(**news_data.dict())
    await db.news_articles.insert_one(news.dict())
    return news

@api_router.get("/news", response_model=List[NewsArticle])
async def get_news_articles():
    """Get all news articles"""
    articles = await db.news_articles.find().sort("created_at", -1).to_list(100)
    return articles

@api_router.get("/news/{news_id}", response_model=NewsArticle)
async def get_news_article(news_id: str):
    """Get a specific news article"""
    article = await db.news_articles.find_one({"id": news_id})
    if not article:
        raise HTTPException(status_code=404, detail="News article not found")
    return article

@api_router.put("/news/{news_id}", response_model=NewsArticle)
async def update_news_article(news_id: str, update: NewsArticleUpdate):
    """Update news article content"""
    result = await db.news_articles.update_one(
        {"id": news_id},
        {
            "$set": {
                "generated_content": update.generated_content,
                "updated_at": datetime.now(timezone.utc).isoformat()
            }
        }
    )
    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="News article not found")
    
    article = await db.news_articles.find_one({"id": news_id})
    return article

@api_router.delete("/news/{news_id}")
async def delete_news_article(news_id: str):
    """Delete a news article"""
    result = await db.news_articles.delete_one({"id": news_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="News article not found")
    return {"message": "News article deleted successfully"}

@api_router.post("/news/generate")
async def generate_news_article(request: NewsArticleGenerate):
    """Generate crypto news summary using AI"""
    try:
        # Get source content
        source_content = request.source_content
        
        # If source is URL, scrape the content
        if request.source_type == "url":
            try:
                response = requests.get(request.source_content, timeout=15, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                response.raise_for_status()
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Remove script and style elements
                for script in soup(["script", "style", "nav", "footer", "header", "aside"]):
                    script.decompose()
                
                # Get title
                title = soup.find('title')
                title_text = title.get_text().strip() if title else ""
                
                # Get main content
                main_content = ""
                content_areas = soup.find_all(['article', 'main', 'div'], class_=lambda x: x and any(c in str(x).lower() for c in ['content', 'article', 'post', 'entry']))
                if content_areas:
                    main_content = ' '.join([area.get_text(separator=' ', strip=True) for area in content_areas])
                else:
                    paragraphs = soup.find_all('p')
                    main_content = ' '.join([p.get_text(separator=' ', strip=True) for p in paragraphs])
                
                source_content = f"Title: {title_text}\n\nContent:\n{main_content}"
                
            except Exception as e:
                raise HTTPException(status_code=400, detail=f"Kh√¥ng th·ªÉ c√†o n·ªôi dung t·ª´ URL: {str(e)}")
        
        # Determine style based on choice
        style_instruction = ""
        if request.style_choice == "style1":
            style_instruction = """
üîπ PHONG C√ÅCH 1: VƒÉn xu√¥i + c√≥ li·ªát k√™
> D√†nh cho tin c√≥ s·ªë li·ªáu, d·ªØ ki·ªán, c·∫≠p nh·∫≠t th·ªã tr∆∞·ªùng.

**C·∫§U TR√öC CHI TI·∫æT:**
1. **M·ªü ƒë·∫ßu:** üî• Ti√™u ƒë·ªÅ gi·∫≠t t√≠t, nh·∫•n m·∫°nh con s·ªë ho·∫∑c s·ª± ki·ªán ch√≠nh
2. **T√≥m t·∫Øt:** M·ªôt ƒëo·∫°n ng·∫Øn t√≥m b·ªëi c·∫£nh ho·∫∑c ngu·ªìn tin  
3. **Tr·ªçng t√¢m:** 2‚Äì3 d√≤ng li·ªát k√™, d√πng icon üëâ
4. **Ph√¢n t√≠ch:** Gi·∫£i th√≠ch √Ω nghƒ©a, xu h∆∞·ªõng ho·∫∑c t√°c ƒë·ªông
5. **H√†m √Ω/D·ª± b√°o:** ‚û°Ô∏è N√™u h∆∞·ªõng ƒëi ti·∫øp theo ho·∫∑c kh·∫£ nƒÉng x·∫£y ra
6. **K·∫øt b√†i:** C√¢u h·ªèi m·ªü th√¢n m·∫≠t, c√≥ emoji
   > V√≠ d·ª•: "AE nghƒ© sao? üòÖ" ho·∫∑c "Li·ªáu ƒë√¢y l√† t√≠n hi·ªáu gom h√†ng kh√¥ng AE? üòÖ"

**TONE:** Nhanh, s√∫c t√≠ch, g·∫ßn g≈©i, r√µ √Ω.
"""
        elif request.style_choice == "style2":
            style_instruction = """
üîπ PHONG C√ÅCH 2: VƒÉn xu√¥i, kh√¥ng li·ªát k√™
> D√†nh cho tin nh·∫≠n ƒë·ªãnh, xu h∆∞·ªõng, ch√≠nh s√°ch, ph√°t bi·ªÉu, h·ª£p t√°c.

**C·∫§U TR√öC CHI TI·∫æT:**
1. **M·ªü ƒë·∫ßu:** üî• + ti√™u ƒë·ªÅ ƒë·ªãnh h∆∞·ªõng (xu h∆∞·ªõng, nh√¢n v·∫≠t, h√†nh ƒë·ªông)
2. **D·∫´n d·∫Øt:** Gi·ªõi thi·ªáu nh√¢n v·∫≠t/ch·ªß th·ªÉ + h√†nh ƒë·ªông c·ª• th·ªÉ
3. **B·ªëi c·∫£nh:** ü§î Gi·∫£i th√≠ch ng·∫Øn g·ªçn v√¨ sao ƒë√¢y l√† s·ª± ki·ªán ƒë√°ng ch√∫ √Ω
4. **Ph√°t bi·ªÉu/C·ªßng c·ªë:** C√≥ th·ªÉ tr√≠ch d·∫´n 1 c√¢u n√≥i ho·∫∑c quan ƒëi·ªÉm
5. **K·∫øt b√†i:** Hai c√¢u cu·ªëi t√°ch ri√™ng, c√πng nh·ªãp, k√≠ch th√≠ch t∆∞∆°ng t√°c
   > V√≠ d·ª•:
   > Cu·ªôc chi·∫øn n√†y kh√¥ng ch·ªâ xoay quanh m·ªôt c√° nh√¢n.
   > Li·ªáu Nh√† Tr·∫Øng c√≥ ƒëang c·ªë gia tƒÉng ·∫£nh h∆∞·ªüng l√™n Fed? AE nghƒ© sao? üòÖ

**TONE:** M·∫°ch l·∫°c, t·ª± nhi√™n, c√≥ ch·∫•t b√¨nh lu·∫≠n nh·∫π.
"""
        else:  # auto
            style_instruction = """
üîπ T·ª∞ ƒê·ªòNG CH·ªåN STYLE d·ª±a v√†o n·ªôi dung:
- N·∫øu tin c√≥ nhi·ªÅu **s·ªë li·ªáu/d·ªØ ki·ªán/metrics/c·∫≠p nh·∫≠t th·ªã tr∆∞·ªùng** ‚Üí ch·ªçn Phong c√°ch 1 (c√≥ li·ªát k√™)
- N·∫øu tin v·ªÅ **ch√≠nh s√°ch/xu h∆∞·ªõng/nh·∫≠n ƒë·ªãnh/ph√°t bi·ªÉu/h·ª£p t√°c** ‚Üí ch·ªçn Phong c√°ch 2 (kh√¥ng li·ªát k√™)

**PHONG C√ÅCH 1 (VƒÉn xu√¥i + li·ªát k√™):**
C·∫•u tr√∫c: üî• M·ªü ƒë·∫ßu ‚Üí T√≥m t·∫Øt ‚Üí üëâ Tr·ªçng t√¢m (list) ‚Üí Ph√¢n t√≠ch ‚Üí ‚û°Ô∏è H√†m √Ω/D·ª± b√°o ‚Üí K·∫øt b√†i (? üòÖ)
Tone: Nhanh, s√∫c t√≠ch, g·∫ßn g≈©i, r√µ √Ω

**PHONG C√ÅCH 2 (VƒÉn xu√¥i, kh√¥ng li·ªát k√™):**  
C·∫•u tr√∫c: üî• M·ªü ƒë·∫ßu + ƒë·ªãnh h∆∞·ªõng ‚Üí D·∫´n d·∫Øt ‚Üí ü§î B·ªëi c·∫£nh ‚Üí Ph√°t bi·ªÉu/C·ªßng c·ªë ‚Üí 2 c√¢u cu·ªëi t√°ch ri√™ng (? üòÖ)
Tone: M·∫°ch l·∫°c, t·ª± nhi√™n, c√≥ ch·∫•t b√¨nh lu·∫≠n nh·∫π
"""
        
        # System message for News Generator with enhanced context engineering
        system_message = f"""B·∫°n l√† m·ªôt Crypto News Generator AI chuy√™n nghi·ªáp, t·∫°o b·∫£n tin crypto t·ª± ƒë·ªông b·∫±ng ti·∫øng Vi·ªát.

üéØ M·ª§C TI√äU:
T·∫°o b·∫£n tin crypto ng·∫Øn g·ªçn (~150 t·ª´), ƒë√∫ng tone m·∫°ng x√£ h·ªôi (Twitter/Telegram/LinkedIn), d·ª±a tr√™n n·ªôi dung g·ªëc ti·∫øng Anh.
Output: B·∫£n tin ti·∫øng Vi·ªát s√∫c t√≠ch, c√≥ c·∫£m x√∫c, logic, d·ªÖ ƒë·ªçc v√† d·ªÖ viral.

üé≠ BRAND VOICE:
**Th√¥ng minh ‚Äì Th√¢n thi·ªán ‚Äì T·ª± tin ‚Äì Kh√¥ng d∆∞ th·ª´a**
- B·∫°n l√† m·ªôt "chi·∫øn h·ªØu" c√πng b√†n lu·∫≠n tin t·ª©c crypto v·ªõi ng∆∞·ªùi ƒë·ªçc
- Gi·ªçng vƒÉn nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n am hi·ªÉu, kh√¥ng h·ªçc thu·∫≠t, g·∫ßn g≈©i
- T·∫°o c·∫£m x√∫c, nh·∫•n m·∫°nh s·ª± ki·ªán ch√≠nh
- Khuy·∫øn kh√≠ch t∆∞∆°ng t√°c qua c√¢u h·ªèi m·ªü

üì∞ PHONG C√ÅCH VI·∫æT:
{style_instruction}

‚öôÔ∏è QUY T·∫ÆC & CHI TI·∫æT K·ª∏ THU·∫¨T:
- **Gi·ªØ nguy√™n t√™n b√°o:** v√≠ d·ª• *Financial Times (Anh)*
- **Emoji:** ch·ªâ d√πng 2‚Äì3 c√°i ch√≠nh (üî• ü§î üëâ ‚û°Ô∏è üòÖ)
- **KH√îNG th√™m th√¥ng tin ngo√†i b√†i g·ªëc** - ch·ªâ t√≥m t·∫Øt v√† di·ªÖn ƒë·∫°t l·∫°i
- **KH√îNG d√πng meme ho·∫∑c emoji l·ªë** - gi·ªØ tinh t·∫ø
- **Quote:** c√≥ th·ªÉ ƒë·ªÉ nguy√™n ti·∫øng Anh ho·∫∑c d·ªãch t·ª± nhi√™n
- **ƒê·ªô d√†i:** 120‚Äì160 t·ª´ (ch·∫∑t ch·∫Ω)
- **K·∫øt b√†i:** Lu√¥n c√≥ c√¢u h·ªèi m·ªü kh∆°i g·ª£i t∆∞∆°ng t√°c + emoji üòÖ

üì§ OUTPUT FORMATTING RULES:
- **KH√îNG** b·∫Øt ƒë·∫ßu b·∫±ng: "Ch·∫Øc ch·∫Øn r·ªìi", "D∆∞·ªõi ƒë√¢y l√†", "T·∫•t nhi√™n r·ªìi", "Sure", "Here's your text"
- B·∫Øt ƒë·∫ßu **NGAY L·∫¨P T·ª®C** v·ªõi n·ªôi dung (ti√™u ƒë·ªÅ ho·∫∑c c√¢u m·ªü ƒë·∫ßu)
- **KH√îNG** bao g·ªìm b·∫•t k·ª≥ b√¨nh lu·∫≠n ngo√†i l·ªÅ, gi·∫£i th√≠ch, ho·∫∑c c√¢u chuy·ªÉn ti·∫øp
- Output ph·∫£i tr√¥ng nh∆∞ ƒë∆∞·ª£c vi·∫øt tr·ª±c ti·∫øp ƒë·ªÉ xu·∫•t b·∫£n, kh√¥ng c·∫ßn ch·ªânh s·ª≠a

üí° V√ç D·ª§ M·∫™U K·∫æT B√ÄI:
- "AE nghƒ© sao? üòÖ"
- "Li·ªáu ƒë√¢y l√† t√≠n hi·ªáu gom h√†ng kh√¥ng AE? üòÖ"  
- "Kh·∫•n c√°c anh ƒë·∫©y v·ªôi cho AE toai v·ªÅ b·ªù r·ªìi v·ª° sau c≈©ng ƒë∆∞·ª£c üòÖ"
- "AE nghƒ© sao, c√∫ s·∫≠p n√†y l√† d·∫•u hi·ªáu c·∫£nh b√°o k·∫øt m√πa hay reset game cho nh·∫π thuy·ªÅn n√†o? üòÖ"
- "Anh em ƒëang nh·∫Øm t·ªõi d·ª± √°n n√†o b√™n h·ªá Base v√† ph√¢n kh√∫c AI ƒë√≥, share v·ªõi c·ªông ƒë·ªìng n√†o üòÖ"

H√£y t·∫°o b·∫£n tin theo ƒë√∫ng phong c√°ch ƒë√£ ch·ªâ ƒë·ªãnh, gi·ªØ ƒë·ªô d√†i 120-160 t·ª´, v√† ƒë·∫£m b·∫£o tone th√¢n thi·ªán nh∆∞ ƒëang tr√≤ chuy·ªán v·ªõi chi·∫øn h·ªØu."""

        # Build user message
        user_message_text = f"""N·ªôi dung ngu·ªìn (ti·∫øng Anh):

{source_content}"""
        
        if request.opinion:
            user_message_text += f"""

Nh·∫≠n x√©t/Opinion t·ª´ ng∆∞·ªùi d√πng:
{request.opinion}"""
        
        user_message_text += "\n\nH√£y t·∫°o b·∫£n tin crypto summary theo style ƒë√£ ch·ªâ ƒë·ªãnh. Nh·ªõ: B·∫ÆT ƒê·∫¶U NGAY v·ªõi n·ªôi dung b·∫£n tin, KH√îNG th√™m l·ªùi m·ªü ƒë·∫ßu hay gi·∫£i th√≠ch."
        
        # Initialize Gemini chat
        chat = LlmChat(
            api_key=GOOGLE_API_KEY,
            session_id=f"news_{uuid.uuid4().hex[:8]}",
            system_message=system_message
        ).with_model("gemini", "gemini-2.5-pro")
        
        # Generate content
        user_message = UserMessage(user_message_text)
        response = await chat.send_message(user_message)
        
        # Create and save news article
        news_article = NewsArticle(
            source_content=request.source_content,
            opinion=request.opinion,
            style_choice=request.style_choice,
            generated_content=response.strip(),
            source_type=request.source_type
        )
        
        await db.news_articles.insert_one(news_article.dict())
        
        return news_article
    
    except Exception as e:
        logging.error(f"News generation error: {e}")
        raise HTTPException(status_code=500, detail=f"News generation failed: {str(e)}")

# Social-to-Website Post endpoints
@api_router.post("/social-posts", response_model=SocialPost)
async def create_social_post(post_data: SocialPostGenerate):
    """Create a new social post without generating content"""
    post = SocialPost(**post_data.dict())
    await db.social_posts.insert_one(post.dict())
    return post

@api_router.get("/social-posts", response_model=List[SocialPost])
async def get_social_posts():
    """Get all social posts"""
    posts = await db.social_posts.find().sort("created_at", -1).to_list(length=100)
    return posts

@api_router.get("/social-posts/{post_id}", response_model=SocialPost)
async def get_social_post(post_id: str):
    """Get a specific social post"""
    post = await db.social_posts.find_one({"id": post_id})
    if not post:
        raise HTTPException(status_code=404, detail="Social post not found")
    return post

@api_router.put("/social-posts/{post_id}", response_model=SocialPost)
async def update_social_post(post_id: str, update: SocialPostUpdate):
    """Update social post content"""
    result = await db.social_posts.update_one(
        {"id": post_id},
        {
            "$set": {
                "generated_content": update.generated_content,
                "updated_at": datetime.now(timezone.utc)
            }
        }
    )
    
    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="Social post not found")
    
    post = await db.social_posts.find_one({"id": post_id})
    return post

@api_router.delete("/social-posts/{post_id}")
async def delete_social_post(post_id: str):
    """Delete a social post"""
    result = await db.social_posts.delete_one({"id": post_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Social post not found")
    return {"message": "Social post deleted successfully"}

@api_router.post("/social-posts/generate")
async def generate_social_post(request: SocialPostGenerate):
    """Generate social-to-website post using AI"""
    try:
        # Get website content based on source type
        website_content = ""
        
        if request.source_type == "url" and request.website_link:
            # Scrape website content from URL
            try:
                response = requests.get(request.website_link, timeout=15, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Remove script and style elements
                for script in soup(["script", "style"]):
                    script.decompose()
                
                # Get text content
                website_content = soup.get_text(separator=' ', strip=True)
                # Limit content length
                website_content = website_content[:5000]
                
            except Exception as e:
                logging.error(f"Error scraping website: {e}")
                raise HTTPException(status_code=400, detail=f"Kh√¥ng th·ªÉ c√†o n·ªôi dung t·ª´ URL: {str(e)}")
        
        elif request.source_type == "text" and request.website_content:
            # Use provided text content
            website_content = request.website_content[:5000]
        
        if not website_content:
            raise HTTPException(status_code=400, detail="Vui l√≤ng cung c·∫•p URL ho·∫∑c n·ªôi dung website")
        
        # Build system message based on context engineering
        system_message = """B·∫°n l√† m·ªôt AI chuy√™n t·∫°o b√†i ƒëƒÉng social media ƒë·ªÉ d·∫´n traffic v·ªÅ website (GFI Research).

üéØ M·ª§C TI√äU:
T·∫°o b√†i vi·∫øt ƒëƒÉng tr√™n c√°c n·ªÅn t·∫£ng social (X, Facebook, LinkedIn) ƒë·ªÉ d·∫´n ng∆∞·ªùi ƒë·ªçc v·ªÅ website, n∆°i c√≥ b√†i ph√¢n t√≠ch chi ti·∫øt.
- ƒê·ªô d√†i: 150‚Äì180 t·ª´
- C·∫•u tr√∫c: 3‚Äì4 ƒëo·∫°n ng·∫Øn
- Tone: Chuy√™n nghi·ªáp ‚Äì d·ªÖ ƒë·ªçc ‚Äì gi√†u th√¥ng tin (gi·ªëng KOL crypto)

üìù C·∫§U TR√öC B√ÄI VI·∫æT (4 PH·∫¶N):

1Ô∏è‚É£ **TITLE (Hook nh√† ƒë·∫ßu t∆∞)**
   - Thu h√∫t ƒë·∫ßu ti√™n, ch·ª©a y·∫øu t·ªë "gi·∫≠t nh·∫π"
   - C√≥ s·ªë li·ªáu ho·∫∑c c√¢u h·ªèi g·ª£i t√≤ m√≤
   - C√≥ th·ªÉ d√πng ch·ªØ in hoa, icon, s·ªë li·ªáu l·ªõn
   - V√≠ d·ª•: "üî• G·ªçi v·ªën 130 TRI·ªÜU ƒê√î v·ªõi ƒë·ªãnh gi√° 1 T·ª∂ ƒê√î ‚Äì D·ª± √°n n√†y c√≥ g√¨ m√† 'n·ªï' c·∫£ X?"

2Ô∏è‚É£ **GI·ªöI THI·ªÜU D·ª∞ √ÅN**
   - Cung c·∫•p b·ªëi c·∫£nh v√† t√≥m t·∫Øt trong 1‚Äì2 c√¢u
   - Tr·∫£ l·ªùi: "D·ª± √°n n√†y l√† g√¨, gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†o, v√† v√¨ sao ƒë∆∞·ª£c ch√∫ √Ω?"

3Ô∏è‚É£ **ƒêI·ªÇM N·ªîI B·∫¨T/R√í R·ªà**
   - Ti·∫øt l·ªô chi ti·∫øt g√¢y t√≤ m√≤: g·ªçi v·ªën, tranh lu·∫≠n, c√¥ng ngh·ªá, nh√¢n v·∫≠t, insight
   - D·∫°ng c√¢u t·ª± nhi√™n, c√≥ th·ªÉ d√πng icon (‚ö°, ü§î, üí∏...)
   - V√≠ d·ª•: "üò≥ Nh∆∞ng nh√¨n on-chain l·∫°i th·∫•y m·ªôt c√¢u chuy·ªán kh√°c..."

4Ô∏è‚É£ **CTA (Call to Action)**
   - ƒê∆∞a ng∆∞·ªùi ƒë·ªçc v·ªÅ website
   - K·∫øt th√∫c b·∫±ng c√¢u h·ªèi ho·∫∑c g·ª£i m·ªü
   - V√≠ d·ª•: "C√πng GFI t√¨m hi·ªÉu t·∫°i b√†i vi·∫øt n√†y üëá"

üé® TONE & BRAND VOICE:
- **Phong c√°ch:** Chuy√™n nghi·ªáp, d·ªÖ ƒë·ªçc, gi√†u th√¥ng tin
- **ƒê·ªëi t∆∞·ª£ng:** Nh√† ƒë·∫ßu t∆∞, ng∆∞·ªùi quan t√¢m crypto
- **Gi·ªëng:** C√°c KOL crypto h√†ng ƒë·∫ßu
- **ƒê·ªô d√†i ch·∫∑t ch·∫Ω:** 150‚Äì180 t·ª´

‚öôÔ∏è QUY T·∫ÆC K·ª∏ THU·∫¨T:
- S·ªë ƒëo·∫°n: 3‚Äì4 ƒëo·∫°n ng·∫Øn
- Y·∫øu t·ªë thu h√∫t: S·ªë li·ªáu, c√¢u h·ªèi, ch·ªØ in hoa, icon
- M·ª•c ƒë√≠ch: D·∫´n traffic v·ªÅ website
- CTA: Lu√¥n c√≥ v√† r√µ r√†ng, k√®m link v·ªÅ website

üí° LOGIC FILL SYSTEM:
1. N·∫øu user ƒëi·ªÅn title ‚Üí gi·ªØ nguy√™n. N·∫øu tr·ªëng ‚Üí AI sinh hook gi·∫≠t nh·∫π v·ªõi s·ªë li·ªáu/c√¢u h·ªèi
2. N·∫øu user ƒëi·ªÅn gi·ªõi thi·ªáu ‚Üí d√πng nguy√™n vƒÉn. N·∫øu tr·ªëng ‚Üí AI t√≥m t·∫Øt t·ª´ web content
3. N·∫øu user ƒëi·ªÅn ƒëi·ªÉm n·ªïi b·∫≠t ‚Üí gi·ªØ nguy√™n. N·∫øu tr·ªëng ‚Üí AI ch·ªçn insight h·∫•p d·∫´n nh·∫•t t·ª´ b√†i web
4. Th√™m CTA r√µ r√†ng h∆∞·ªõng v·ªÅ website, k√®m link

üì§ OUTPUT FORMATTING RULES:
- **KH√îNG** b·∫Øt ƒë·∫ßu b·∫±ng: "Ch·∫Øc ch·∫Øn r·ªìi", "D∆∞·ªõi ƒë√¢y l√†", "Sure", "Here's your text"
- B·∫Øt ƒë·∫ßu **NGAY L·∫¨P T·ª®C** v·ªõi n·ªôi dung (title/c√¢u m·ªü ƒë·∫ßu)
- **KH√îNG** bao g·ªìm b√¨nh lu·∫≠n ngo√†i l·ªÅ, gi·∫£i th√≠ch
- Output ph·∫£i s·∫µn s√†ng ƒë·ªÉ ƒëƒÉng l√™n social media ngay

H√£y t·∫°o b√†i vi·∫øt social post theo ƒë√∫ng c·∫•u tr√∫c v√† tone ƒë√£ ch·ªâ ƒë·ªãnh."""

        # Build user message
        user_message_parts = []
        
        # Add website content
        if website_content:
            user_message_parts.append(f"N·ªòI DUNG T·ª™ WEBSITE:\n{website_content[:3000]}")
        
        # Add link if provided
        if request.website_link:
            user_message_parts.append(f"\nLINK WEBSITE: {request.website_link}")
        
        # Add user inputs if provided
        if request.title:
            user_message_parts.append(f"\nTITLE (do user cung c·∫•p):\n{request.title}")
        else:
            user_message_parts.append("\nTITLE: (ƒë·ªÉ tr·ªëng - AI t·ª± sinh hook gi·∫≠t t√≠t)")
        
        if request.introduction:
            user_message_parts.append(f"\nGI·ªöI THI·ªÜU (do user cung c·∫•p):\n{request.introduction}")
        else:
            user_message_parts.append("\nGI·ªöI THI·ªÜU: (ƒë·ªÉ tr·ªëng - AI t·ª± t√≥m t·∫Øt d·ª± √°n)")
        
        if request.highlight:
            user_message_parts.append(f"\nƒêI·ªÇM N·ªîI B·∫¨T (do user cung c·∫•p):\n{request.highlight}")
        else:
            user_message_parts.append("\nƒêI·ªÇM N·ªîI B·∫¨T: (ƒë·ªÉ tr·ªëng - AI t·ª± ch·ªçn insight h·∫•p d·∫´n)")
        
        user_message_parts.append("\n\nH√£y t·∫°o b√†i social post ho√†n ch·ªânh v·ªõi CTA d·∫´n v·ªÅ website. Nh·ªõ: B·∫ÆT ƒê·∫¶U NGAY v·ªõi n·ªôi dung, KH√îNG th√™m l·ªùi m·ªü ƒë·∫ßu.")
        
        user_message_text = "\n".join(user_message_parts)
        
        # Initialize Gemini chat
        chat = LlmChat(
            api_key=GOOGLE_API_KEY,
            session_id=f"social_{uuid.uuid4().hex[:8]}",
            system_message=system_message
        ).with_model("gemini", "gemini-2.5-pro")
        
        # Generate content
        user_message = UserMessage(user_message_text)
        response = await chat.send_message(user_message)
        
        # Create and save social post
        social_post = SocialPost(
            website_link=request.website_link,
            website_content=request.website_content,
            source_type=request.source_type,
            title=request.title,
            introduction=request.introduction,
            highlight=request.highlight,
            generated_content=response.strip()
        )
        
        await db.social_posts.insert_one(social_post.dict())
        
        return social_post
    
    except Exception as e:
        logging.error(f"Social post generation error: {e}")
        raise HTTPException(status_code=500, detail=f"Social post generation failed: {str(e)}")

# Include router
app.include_router(api_router)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=os.environ.get('CORS_ORIGINS', '*').split(','),
    allow_methods=["*"],
    allow_headers=["*"],
)

# Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()